'''Sync Method and Sync Location base classes'''

# allow class name being used before being fully defined (like in same class):
from __future__ import annotations

import json
import base64

from kiss_cf import logging
from .storage_master import StorageMaster, DerivingStorageMaster
from ._meta_data import MetaDataStorable


class KissStorageSyncException(Exception):
    ''' General exception from storage Sync '''


class KissChangeOnBothSidesException(Exception):
    ''' Files were changed on both storage locations sides when executing
    synchronization. '''


class SyncData(dict):
    ''' Synchronization data (as in: <some file>.sync)

    Synchronization data is stored in human readable JSON files to allow manual
    inspection.

    Data in ['location'] is with respect to the synchronization partner. When
    looking at file.sync in location A and seeing a UUID for location B, this
    implies: the latest sync between A and B was done based on the file state
    with this UUID.
    '''
    def __init__(self):
        super().__init__()
        # version for potential later upgrade handling:
        self.__setitem__('version', 1)
        # Locations (by their ID) with latest timestamp of this file.
        self.__setitem__('location', {})

    @classmethod
    def _get_location_template(cls) -> dict:
        ''' Template for location data '''
        # IMORTANT: if you change details here, you might need to update the
        # version in __init__ and handle for compatibility.
        return {
            # UUID is the main decision criterium for the sync algorithm.
            'uuid': '',
            # Timestamp was origingally intended to be used but is not reliable
            # in cases where updates/sync happen within seconds (as visible in
            # automated test cases). It is still kept and maintained since it
            # is valuable for manual inspections.
            'timestamp': None
            }

    # def set_location_timestamp(self,
    #                           location: StorageLocation,
    #                           timestamp: datetime):
    #    ''' Set last seen timestamp of this file in other location. '''
    #    str_timestamp = timestamp.isoformat()
    #    loc_id = location.get_id()
    #    if loc_id not in self['location']:
    #        self['location'][loc_id] = self._get_location_template()
    #    self['location'][loc_id]['timestamp'] = str_timestamp

    # Method excluded from coverage since it is currently unused in KISS_CF and
    # not intended for usage outside of KISS_CF. See the comment in
    # _get_location_template() on timestamp.
    # def get_location_timestamp(self,
    #                           location: StorageLocation
    #                           ) -> datetime | None:
    #    ''' Get last seen timestamp of this file in other location.
#
    #    Returns None if location is not known within this sync file.
    #    '''
    #    loc_id = location.get_id()
    #    if loc_id not in self['location']:
    #        return None
    #    return datetime.fromisoformat(self['location'][loc_id]['timestamp'])

    def set_location_uuid(self, storage: StorageMaster, uuid: bytes):
        ''' Set UUID of file in other location. '''
        str_uuid = base64.b64encode(uuid).decode('utf-8')
        loc_id = storage.get_id()
        if loc_id not in self['location']:
            self['location'][loc_id] = self._get_location_template()
        self['location'][loc_id]['uuid'] = str_uuid

    def get_location_uuid(self, storage: StorageMaster) -> bytes:
        ''' Get UUID of file in other location.

        Returns b'' if location is not known within this sync file.
        '''
        loc_id = storage.get_id()
        if loc_id not in self['location']:
            return b''
        uuid_str = self['location'][loc_id]['uuid']
        return base64.b64decode(uuid_str)

    @classmethod
    def from_bytes(cls, data: bytes) -> SyncData:
        ''' Construct a SyncData object from bytes

        Correct bytes are generated by to_bytes()
        '''
        obj = cls()
        obj.update(json.loads(data.decode('utf-8')))
        return obj

    def to_bytes(self):
        ''' Get bytes that represent the sync state

        SyncState can be reconstructed via SyncData.from_bytes().
        '''
        json_out = json.dumps(self, indent=4, separators=(',', ': '))
        return bytes(json_out, encoding='utf-8')


log = logging.getLogger(__name__)



# Pyhon dirsync:
# https://github.com/tkhyn/dirsync/blob/develop/dirsync/syncer.py
#  * Uses timestamps (stat)
#  * Uses filecmp (stat: type, size, modification time; plus eventually
#    content)

# TODO: How does the sync consider removing files again??

# TODO: storage has to resolve concurrent access problems (reading while
# writing, writing while reading, two writing)


def sync(master_a: StorageMaster | DerivingStorageMaster,
         master_b: StorageMaster | DerivingStorageMaster):
    ''' Synchronize items from two StorageMasters

    Check timestamps of files on both locations and forward to the refined
    SyncMechanism.sync(). Files on the remote location that do not match a
    Storable will be ignored.
    '''
    # TODO: add proper get_registered_files() interface to StorageLocation
    file_list = set(
        list(master_a.get_file_list()) +
        list(master_b.get_file_list()))
    log.debug(f'Starting sync between {master_a} and {master_b}')

    # ## Decision Stage 1: File Existance
    for file in file_list:
        storage_a = master_a.get_storage(file)
        storage_b = master_b.get_storage(file)
        meta_a = master_a.get_meta_data(file)
        meta_b = master_b.get_meta_data(file)
        exists_a = storage_a.exists()
        exists_b = storage_b.exists()
        if not exists_a and not exists_b:
            # can happen if file was not created, yet
            log.debug(f'File {file} not existing on both sides')
            continue
        if not exists_b:
            log.debug(f'File {file} not existing on {master_b}')
            _sync_file(file, master_a, master_b, meta_a, meta_b)
            continue
        if not exists_a:
            log.debug(f'File {file} not existing on {master_a}')
            _sync_file(file, master_b, master_a, meta_b, meta_a)
            continue
        # Both files exist. We continue normally.

        # ## Decision Stage 2: Decision based on UUID
        # Get file uuid's

        # read sync data
        sync_data_a = _load_sync_data(file, master_a)
        sync_data_b = _load_sync_data(file, master_b)
        # timestamps and uuid in sync data
        last_uuid_a = sync_data_a.get_location_uuid(master_b)
        last_uuid_b = sync_data_b.get_location_uuid(master_a)

        # Defensive implementation: this case cannot happen.
        # StorageLocations should generate a UUID even if the file
        # initially has none.
        if (not last_uuid_b or
                not last_uuid_a):
            raise KissStorageSyncException(
                f'[{file}] exists on both locaions but StorageLocation did '
                f'not return a UUID. This should not happen. Please '
                f'reconsider the StorageLocation implementation. '
                f'You could alternatively remove the file from one of the '
                f'locations')
        if (meta_a.uuid != last_uuid_a and
                meta_b.uuid != last_uuid_b):
            raise KissChangeOnBothSidesException(
                f'[{file}] changed on both sides. Not yet supported.')
        if meta_a.uuid != last_uuid_a:
            _sync_file(file, master_a, master_b, meta_a, meta_b)
            # logging in _sync_file
        elif meta_b.uuid != last_uuid_b:
            _sync_file(file, master_b, master_a, meta_b, meta_a)
            # TODO: this A/B and local/remote has to be straightened up.
            # logging in _sync_file
        else:
            log.debug(f'File {file} did not change.')


def _sync_file(file,
               source: StorageMaster | DerivingStorageMaster,
               target: StorageMaster | DerivingStorageMaster,
               source_meta: MetaDataStorable,
               target_meta: MetaDataStorable):

    log.info(f'Updating {file} from {source} to {target}')

    # TODO UPGRADE: mark files "not readable" during sync
    # self.__mark_file_in_sync

    # get data
    data = source.get_storage(file, create=False).load()
    # source_timestamp = source._get_location_timestamp(file)
    # source_uuid = source.get_uuid(file)
    source_sync_data = _load_sync_data(file, source)

    # write data
    target.get_storage(file, create=False).store(data)
    # update meta data:
    target_meta.uuid = source_meta.uuid
    target_meta.store()
    # target_timestamp = target._get_location_timestamp(file)
    target_sync_data = _load_sync_data(file, target)

    # update source sync data:
    # source_sync_data.set_location_timestamp(target, target_timestamp)
    source_sync_data.set_location_uuid(target, source_meta.uuid)
    _store_sync_data(file, source, source_sync_data)
    # update target sync data: source location must now contain timestamp
    # of newly written data
    # target_sync_data.set_location_timestamp(source, source_timestamp)
    target_sync_data.set_location_uuid(source, source_meta.uuid)
    _store_sync_data(file, target, target_sync_data)

    # TODO UPGRADE: unmark files "not readable"
    # self.__mark_sync_done(file, data)


def _load_sync_data(file,
                    storage: StorageMaster | DerivingStorageMaster
                    ) -> SyncData:
    # get sync storage
    if isinstance(storage, DerivingStorageMaster):
        file_storage = storage.get_root_master().get_storage(
            file + '.sync', register=False)
    else:
        file_storage = storage.get_storage(
            file + '.sync', register=False)
    # catch never synced case:
    if not file_storage.exists():
        return SyncData()
    # load data:
    raw_data = file_storage.load()
    # TODO: this behavior is quite poor. Something should be a Storable, here.
    return SyncData.from_bytes(raw_data)


def _store_sync_data(file,
                     storage: StorageMaster | DerivingStorageMaster,
                     sync_data: SyncData):
    # get sync storage
    if isinstance(storage, DerivingStorageMaster):
        file_storage = storage.get_root_master().get_storage(
            file + '.sync', register=False)
    else:
        file_storage = storage.get_storage(
            file + '.sync', register=False)
    raw_data = sync_data.to_bytes()
    file_storage.store(raw_data)
