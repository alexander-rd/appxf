'''Sync Method and Sync Location base classes'''

# allow class name being used before being fully defined (like in same class):
from __future__ import annotations

from datetime import datetime
import json

from kiss_cf import logging
from kiss_cf.storage import StorageLocation


class KissStorageSyncException(Exception):
    ''' General exception from storage Sync '''


class KissChangeOnBothSidesException(Exception):
    ''' Files were changed on both storage locations sides when executing
    synchronization. '''


class SyncData(dict):
    ''' Synchronization data (as in: <some file>.sync)

    Synchronization data is stored in human readable JSON files to allow manual
    inspection.

    Data in ['location'] is with respect to the synchronization partner. When
    looking at file.sync in location A and seeing a UUID for location B, this
    implies: the latest sync between A and B was done based on the file state
    with this UUID.
    '''
    def __init__(self):
        super().__init__()
        # version for potential later upgrade handling:
        self.__setitem__('version', 1)
        # Locations (by their ID) with latest timestamp of this file.
        self.__setitem__('location', {})

    @classmethod
    def _get_location_template(cls) -> dict:
        ''' Template for location data '''
        # IMORTANT: if you change details here, you might need to update the
        # version in __init__ and handle for compatibility.
        return {
            # UUID is the main decision criterium for the sync algorithm.
            'uuid': b'',
            # Timestamp was origingally intended to be used but is not reliable
            # in cases where updates/sync happen within seconds (as visible in
            # automated test cases). It is still kept and maintained since it
            # is valuable for manual inspections.
            'timestamp': None
            }

    def set_location_timestamp(self,
                               location: StorageLocation,
                               timestamp: datetime):
        ''' Set last seen timestamp of this file in other location. '''
        str_timestamp = timestamp.isoformat()
        loc_id = location.get_id()
        if loc_id not in self['location']:
            self['location'][loc_id] = self._get_location_template()
        self['location'][loc_id]['timestamp'] = str_timestamp

    # Method excluded from coverage since it is currently unused in KISS_CF and
    # not intended for usage outside of KISS_CF. See the comment in
    # _get_location_template() on timestamp.
    def get_location_timestamp(self,
                               location: StorageLocation
                               ) -> datetime | None:
        ''' Get last seen timestamp of this file in other location.

        Returns None if location is not known within this sync file.
        '''
        loc_id = location.get_id()
        if loc_id not in self['location']:
            return None
        return datetime.fromisoformat(self['location'][loc_id]['timestamp'])

    def set_location_uuid(self, location: StorageLocation, uuid: bytes):
        ''' Set UUID of file in other location. '''
        str_uuid = uuid.decode('utf-8')
        loc_id = location.get_id()
        if loc_id not in self['location']:
            self['location'][loc_id] = self._get_location_template()
        self['location'][loc_id]['uuid'] = str_uuid

    def get_location_uuid(self, location: StorageLocation) -> bytes:
        ''' Get UUID of file in other location.

        Returns b'' if location is not known within this sync file.
        '''
        loc_id = location.get_id()
        if loc_id not in self['location']:
            return b''
        return self['location'][loc_id]['uuid'].encode('utf-8')

    @classmethod
    def from_bytes(cls, data: bytes) -> SyncData:
        ''' Construct a SyncData object from bytes

        Correct bytes are generated by to_bytes()
        '''
        obj = cls()
        obj.update(json.loads(data.decode('utf-8')))
        return obj

    def to_bytes(self):
        ''' Get bytes that represent the sync state

        SyncState can be reconstructed via SyncData.from_bytes().
        '''
        json_out = json.dumps(self, indent=4, separators=(',', ': '))
        return bytes(json_out, encoding='utf-8')


log = logging.getLogger(__name__)

# TODO: this will not work: the sync algorithm does not know the storage method
# that should apply when storing the file on the location.
#
# Alternative A: Location maintains the storage method.
#  * the deriving methods would need to set the storage method again
#    * !! This implies that the intermediate method should not be used.. ..but
#      the user still has access to it and does not know
#
# Alternative B: The location method is derived
#  * !! Similar problem as above that the the non-derived location is still
#    available. But this time, constructing a method for the same file again
#    would fail.
#    * User may (accidently, of course) set up the same location twice leading
#      to similar problems
#
# Both solutions above are about Location must maintain the storage methods.
#
# (+) Alternative B allows sync(Private, Shared) with files generated in
#     Private while appropriate StorageMethods can be retrieved from
#     SharedLocation by the sync algorithm.
#  * A location should return +the same+ storage method for a file
#  * A shared location could purge it's memory on sync objects. But we don't
#    care much about RAM size for now.
#
# Action plan
#
# * Add BaseLocation with MethodStorage
# * DerivedLocation(BaseLocation, DerivedMethod) << one fits all


def sync(loc_a: StorageLocation,
         loc_b: StorageLocation):
    ''' Synchronize StorageLocations with registered Files

    Check timestamps of files on both locations and forward to the refined
    SyncMechanism.sync(). Files on the remote location that do not match a
    Storable will be ignored.
    '''
    # TODO: add proper get_registered_files() interface to StorageLocation
    file_list = set(
        list(loc_a._file_map.keys()) +
        list(loc_b._file_map.keys()))
    log.debug(f'Starting sync between {loc_a} and {loc_b}')

    # ## Decision Stage 1: File Existance
    for file in file_list:
        local_exists = loc_a.exists(file)
        remote_exists = loc_b.exists(file)
        if not local_exists and not remote_exists:
            # can happen if file was not created, yet
            log.debug(f'File {file} not existing on both sides')
            continue
        if not remote_exists:
            log.debug(f'File {file} not existing on {loc_b}')
            _sync_file(file, loc_a, loc_b)
            continue
        if not local_exists:
            log.debug(f'File {file} not existing on {loc_a}')
            _sync_file(file, loc_b, loc_a)
            continue
        # Both files exist. We continue normally.

        # ## Decision Stage 2: Decision based on UUID
        # Get file uuid's
        local_uuid = loc_a.get_uuid(file)
        remote_uuid = loc_b.get_uuid(file)
        # read sync data
        local_sync_data = _load_sync_data(file, loc_a)
        remote_sync_data = _load_sync_data(file, loc_b)
        # timestamps and uuid in sync data
        last_local_uuid = local_sync_data.get_location_uuid(loc_b)
        last_remote_uuid = remote_sync_data.get_location_uuid(loc_a)

        # Defensive implementation: this case cannot happen.
        # StorageLocations should generate a UUID even if the file
        # initially has none.
        if (not last_remote_uuid or
                not last_local_uuid):
            raise KissStorageSyncException(
                f'[{file}] exists on both locaions but StorageLocation did '
                f'not return a UUID. This should not happen. Please '
                f'reconsider the StorageLocation implementation. '
                f'You could alternatively remove the file from one of the '
                f'locations')
        if (local_uuid != last_local_uuid and
                remote_uuid != last_remote_uuid):
            raise KissChangeOnBothSidesException(
                f'[{file}] changed on both sides. Not yet supported.')
        if local_uuid != last_local_uuid:
            _sync_file(file, loc_a, loc_b)
            # logging in _sync_file
        elif remote_uuid != last_remote_uuid:
            _sync_file(file, loc_b, loc_a)
            # logging in _sync_file
        else:
            log.debug(f'File {file} did not change.')


def _sync_file(file,
               source: StorageLocation,
               target: StorageLocation):

    log.info(f'Updating {file} from {source} to {target}')

    # TODO UPGRADE: mark files "not readable" during sync
    # self.__mark_file_in_sync

    # get data
    data = source.get_storage_method(file, create=False).load()
    source_timestamp = source._get_location_timestamp(file)
    source_uuid = source.get_uuid(file)
    source_sync_data = _load_sync_data(file, source)

    # write data
    target.get_storage_method(file, create=False).store(data)
    target.store(file + '.uuid', source_uuid, straight=True)
    target_timestamp = target._get_location_timestamp(file)
    target_sync_data = _load_sync_data(file, target)

    # update source sync data:
    source_sync_data.set_location_timestamp(target, target_timestamp)
    source_sync_data.set_location_uuid(target, source_uuid)
    _store_sync_data(file, source, source_sync_data)
    # update target sync data: source location must now contain timestamp
    # of newly written data
    target_sync_data.set_location_timestamp(source, source_timestamp)
    target_sync_data.set_location_uuid(source, source_uuid)
    _store_sync_data(file, target, target_sync_data)

    # TODO UPGRADE: unmark files "not readable"
    # self.__mark_sync_done(file, data)


def _load_sync_data(file, location: StorageLocation) -> SyncData:
    # catch never synced case:
    if not location.exists(file + '.sync'):
        return SyncData()
    # load data:
    raw_data = location._load(file + '.sync')
    return SyncData.from_bytes(raw_data)


def _store_sync_data(file, location: StorageLocation, sync_data: SyncData):
    raw_data = sync_data.to_bytes()
    location._store(file + '.sync', raw_data)
